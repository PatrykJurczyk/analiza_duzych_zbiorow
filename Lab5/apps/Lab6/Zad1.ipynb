{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1b4b32-9da4-4e28-882e-4076cd6288df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_NAME'] = \"/opt/spark\"\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "# os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/opt/spark/work-dir/.venv/bin/python3'\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/spark/work-dir/.venv/bin/python3'\n",
    "\n",
    "# można też spróbować wykorzystać moduł findspark do automatycznego odnalezienia miejsca instalacji sparka\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# lub\n",
    "# findspark.init(\"/opt/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa31924-210b-4aaf-967b-362ed3edd6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/16 16:56:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://2069962cbd74:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Create-DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Create-DataFrame>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"Create-DataFrame\").getOrCreate()\n",
    "# konfiguracja z określeniem liczby wątków (2) oraz ilości pamięci do wykorzystania poza stertą interpretera Pythona\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[2]\")\\\n",
    "        .appName(\"Create-DataFrame\")\\\n",
    "        .config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
    "        .config(\"spark.memory.offHeap.size\",\"6g\")\\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1261ac26-6f93-4746-8d0a-b6a484b247a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b1c4cce-9dc0-48a0-996e-34ceba70be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-16 16:56:49--  https://archive.ics.uci.edu/static/public/911/recipe+reviews+and+user+feedback+dataset.zip\n",
      "128.195.10.252ive.ics.uci.edu (archive.ics.uci.edu)... \n",
      "connected. to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified\n",
      "Saving to: ‘recipe+reviews+and+user+feedback+dataset.zip’\n",
      "\n",
      "recipe+reviews+and+     [     <=>            ]   2.02M  1.52MB/s    in 1.3s    \n",
      "\n",
      "2024-12-16 16:56:51 (1.52 MB/s) - ‘recipe+reviews+and+user+feedback+dataset.zip’ saved [2114088]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pobranie spakowanego zbioru za pomocą polecenia systemowego wget\n",
    "# strona datasetu: https://archive.ics.uci.edu/dataset/911/recipe+reviews+and+user+feedback+dataset\n",
    "!wget https://archive.ics.uci.edu/static/public/911/recipe+reviews+and+user+feedback+dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fea644-dc8f-4ed5-b7ad-0c7774a4497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t      Lab6.ipynb\t\t\t\t    Zad1.ipynb\n",
      "employee.csv  recipe+reviews+and+user+feedback+dataset.zip  Zad2.ipynb\n",
      "lab\t      recipe_reviews.zip\n"
     ]
    }
   ],
   "source": [
    "# listujemy zawartość bieżącego folderu\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd7b4cb-d23f-41b2-a83a-caddbd20c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmiana nazwy pliku - nie jest konieczna, ale trzeba zmienić później ścieżkę w kolejnej komórce notatnika\n",
    "!mv recipe+reviews+and+user+feedback+dataset.zip recipe_reviews.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02232619-ea87-44ed-ab20-095ff1036783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wypakowujemy plik do podfolderu data\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"recipe_reviews.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bee47c9-8f08-49d5-9a66-cce08b56b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " parquet  'Recipe Reviews and User Feedback Dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a50b79-3280-4da1-98a8-eb18e9a13c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",recipe_number,recipe_code,recipe_name,comment_id,user_id,user_name,user_reputation,created_at,reply_count,thumbs_up,thumbs_down,stars,best_score,text\n",
      "0,001,14299,Creamy White Chili,sp_aUSaElGf_14299_c_2G3aneMRgRMZwXqIHmSdXSG1hEM,u_9iFLIhMa8QaG,Jeri326,1,1665619889,0,0,0,5,527,\"I tweaked it a little, removed onions because of onion haters in my house, used Italian seasoning instead of just oregano, and use a paprika/ cayenne mix and a little more than the recipe called for.. we like everything a bit more hot. The chili was amazing! It was easy to make and everyone absolutely loved it. It will now be a staple meal in our house.\"\n",
      "1,001,14299,Creamy White Chili,sp_aUSaElGf_14299_c_2FsPC83HtzCsQAtOxlbL6RcaPbY,u_Lu6p25tmE77j,Mark467,50,1665277687,0,7,0,5,724,\"Bush used to have a white chili bean and it made this recipe super simple. I’ve written to them and asked them to please!, bring them back\"\n"
     ]
    }
   ],
   "source": [
    "# sprawdzamy jak wyglądają 3 pierwsze linie pliku, widać, że pierwsza zawiera nagłówki kolumn a dane są oddzielone przecinkiem\n",
    "!head -3 \"lab/Recipe Reviews and User Feedback Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0d3ba2-f410-4701-afbe-a1f7ba13ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = spark.read.csv('./lab/Recipe Reviews and User Feedback Dataset.csv', header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe115c62-aae4-4640-b113-4592d5320bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zad 1\n",
    "# a\n",
    "df_reviews = df_reviews.withColumnRenamed('_c0', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ae002cf-aabc-4d5d-b5a1-1218129fd905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|reply_count|\n",
      "+-----------+\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          3|\n",
      "|          2|\n",
      "|          2|\n",
      "|          2|\n",
      "|          2|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# b\n",
    "df_reviews.select('reply_count').orderBy(df_reviews['reply_count'], ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69f9a7db-9684-4573-bb1d-a2e6b521e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|recipe_code|sum(best_score)|\n",
      "+-----------+---------------+\n",
      "|       2832|          98863|\n",
      "|      14299|          85497|\n",
      "|      17826|          64880|\n",
      "|       3309|          64247|\n",
      "|      21444|          60755|\n",
      "|      32480|          59867|\n",
      "|      12540|          59195|\n",
      "|       2912|          54032|\n",
      "|      42083|          51975|\n",
      "|      19731|          47905|\n",
      "+-----------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# c\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Rzutowanie kolumny 'best_score' na typ numeryczny (np. IntegerType)\n",
    "df_reviews = df_reviews.withColumn('best_score', col('best_score').cast('int'))\n",
    "\n",
    "# Teraz wykonaj grupowanie i sumowanie\n",
    "df_reviews.groupBy('recipe_code').sum('best_score').orderBy('sum(best_score)', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2c3d4a7-1143-44b3-8a74-2c0e1a6fb3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|recipe_code|sum(reply_count)|\n",
      "+-----------+----------------+\n",
      "|       2832|              16|\n",
      "|        414|              13|\n",
      "|      32480|              12|\n",
      "|      14299|              10|\n",
      "|      18345|              10|\n",
      "|       8202|               9|\n",
      "|      12003|               8|\n",
      "|      41095|               8|\n",
      "|       1324|               8|\n",
      "|       8431|               6|\n",
      "+-----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# d\n",
    "# Rzutowanie kolumny 'reply_count' na typ numeryczny (np. IntegerType)\n",
    "df_reviews = df_reviews.withColumn('reply_count', col('reply_count').cast('int'))\n",
    "\n",
    "df_reviews.groupBy('recipe_code').sum('reply_count').orderBy('sum(reply_count)', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5be1f0-29b4-4a99-9ff7-c87f1bc39427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|stars|count|\n",
      "+-----+-----+\n",
      "|    3|  490|\n",
      "|    0| 1696|\n",
      "| NULL|   86|\n",
      "|    5|13829|\n",
      "|    1|  280|\n",
      "|    4| 1655|\n",
      "|    2|  232|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# e\n",
    "df_reviews.groupBy('stars').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84da2db-cff1-4aac-b9c8-3fc1a4a3e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
