{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e728020-87bb-43d2-9f52-df7b8f11057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/25 10:26:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/25 10:26:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cddbe7311ef5:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark MLlib</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Spark MLlib>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[2]\")\\\n",
    "        .appName(\"Spark MLlib\")\\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46bcdeb4-18d9-4a8c-8f07-3857ec074477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/amrahhasanov23/otodom-pl-flat-prices-in-poland\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Inicjalizacja API Kaggle\n",
    "api = KaggleApi()\n",
    "\n",
    "# Definiowanie nazwy zbioru i ścieżki\n",
    "dataset_name = \"amrahhasanov23/otodom-pl-flat-prices-in-poland\"\n",
    "download_path = os.getcwd()  # Pobranie danych do bieżącego katalogu\n",
    "\n",
    "# Pobieranie danych\n",
    "api.dataset_download_files(dataset_name, path=download_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cdf098-b1d5-4251-b526-def2cf44b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title,Price,Location,Surface,Number_of_Rooms,Floor,Finishing_Condition,Heating,Parking_Space,Balcony_Garden_Terrace,Link,Voivodeship,City\n",
      "2 pokoje 47m2 po remoncie + garderoba + balkon,415000.0,\"ul. Marysińska, Stare Bałuty, Bałuty, Łódź, łódzkie\",47.0,2 ,,do zamieszkania,miejskie,garaż/miejsce parkingowe,balkon,https://www.otodom.pl/pl/oferta/2-pokoje-47m2-po-remoncie-garderoba-balkon-ID4nlGC,Łódzkie,Łódź\n",
      "Właściciel- Ludwiki DD - WIDOK NA ZIELEŃ - 2x gar,2499000.0,\"ul. Ludwiki, Czyste, Wola, Warszawa, mazowieckie\",105.0,4 ,2/8,do wykończenia,miejskie,garaż/miejsce parkingowe,balkon,https://www.otodom.pl/pl/oferta/wlasciciel-ludwiki-dd-widok-na-zielen-2x-gar-ID4mYBj,Mazowieckie,Warszawa\n",
      "\"Sprzedam mieszkanie 60m2, 2 balkony, garderoba\",649000.0,\"ul. Londyńska, Gorzów Wielkopolski, lubuskie\",60.0,3 ,4/4,do zamieszkania,miejskie,,\"balkon, taras\",https://www.otodom.pl/pl/oferta/sprzedam-mieszkanie-60m2-2-balkony-garderoba-ID4nNUL,Lubuskie,Gorzów Wielkopolski\n",
      "\"Wyjątkowy, duży apartament z antresolą\",2108000.0,\"Mrzeżyno, Trzebiatów, gryficki, zachodniopomorskie\",78.3,3 ,4/4,do wykończenia,,garaż/miejsce parkingowe,,https://www.otodom.pl/pl/oferta/wyjatkowy-duzy-apartament-z-antresola-ID4nSve,Zachodniopomorskie,gryficki\n"
     ]
    }
   ],
   "source": [
    "# Sprawdzenie nagłówków pliku\n",
    "!head -5 Otodom_Flat_Listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87f7941-ca50-48c0-8a8f-e61f660148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./Otodom_Flat_Listings.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ef5c3d-ac18-4c6d-8f39-413d4b88fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Surface: string (nullable = true)\n",
      " |-- Number_of_Rooms: string (nullable = true)\n",
      " |-- Floor: string (nullable = true)\n",
      " |-- Finishing_Condition: string (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- Parking_Space: string (nullable = true)\n",
      " |-- Balcony_Garden_Terrace: string (nullable = true)\n",
      " |-- Link: string (nullable = true)\n",
      " |-- Voivodeship: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed50f96-ece1-4b99-b506-9cc140f8ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Konwersja kolumn 'Surface', 'Number_of_Rooms', 'Floor' na float\n",
    "df = df.withColumn(\"Surface\", col(\"Surface\").cast(\"float\")) \\\n",
    "       .withColumn(\"Number_of_Rooms\", col(\"Number_of_Rooms\").cast(\"int\")) \\\n",
    "       .withColumn(\"Floor\", col(\"Floor\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da786daf-ce36-48cf-960e-d659157ae46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Surface: float (nullable = true)\n",
      " |-- Number_of_Rooms: integer (nullable = true)\n",
      " |-- Floor: string (nullable = true)\n",
      " |-- Finishing_Condition: string (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- Parking_Space: string (nullable = true)\n",
      " |-- Balcony_Garden_Terrace: string (nullable = true)\n",
      " |-- Link: string (nullable = true)\n",
      " |-- Voivodeship: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce52f755-ed3c-4f6c-aec0-ac086a9ab92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({\n",
    "    'Surface': df.agg({'Surface': 'avg'}).collect()[0][0],\n",
    "    'Number_of_Rooms': df.agg({'Number_of_Rooms': 'avg'}).collect()[0][0],\n",
    "    'Price': df.agg({'Price': 'avg'}).collect()[0][0],\n",
    "    'Heating': 'Unknown',\n",
    "    'Balcony_Garden_Terrace': 'Unknown',\n",
    "    'Voivodeship': 'Unknown',\n",
    "    'City': 'Unknown',\n",
    "    'Floor': 'Unknown'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c4ef317-7996-4532-83d5-274292578b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Konwertowanie zmiennych kategorycznych na liczby\n",
    "string_columns = ['Heating', 'Balcony_Garden_Terrace', 'Voivodeship', 'City', 'Floor']\n",
    "\n",
    "def convert_string_columns(df, string_columns):\n",
    "    for col_name in string_columns:\n",
    "        indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_index\", handleInvalid=\"skip\")\n",
    "        df = indexer.fit(df).transform(df)\n",
    "    return df\n",
    "\n",
    "df = convert_string_columns(df, string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cddcc4a-08e6-4dc2-91c4-3759595730f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybór cech (features)\n",
    "feature_columns = ['Surface', 'Number_of_Rooms', 'Heating_index', 'Balcony_Garden_Terrace_index', \n",
    "                   'Voivodeship_index', 'City_index', 'Floor_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfdae734-96e4-4f59-adb0-8f60dae326e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Tworzenie wektora cech\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae5b4ebe-82f8-4b1c-999f-ea2e24d4052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolumna celu\n",
    "label_col = \"Price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "930195e7-10ed-4437-bb1e-5a43c955b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Model RandomForest\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=label_col, maxBins=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718300f9-0713-42e2-a258-5e36f438089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Tworzymy pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a29c53a-cd2f-4c8d-aa21-10ab78428180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na dane treningowe i testowe\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f60e67-4d3f-4ff7-a19a-e1257bd942f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dopasowanie modelu\n",
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441b9ff0-bcd6-4d65-9487-1d8d64ae2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przewidywania na zbiorze testowym\n",
    "predictions = model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ab25c0-488b-41f4-a215-32d5e7cd78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Ocena modelu - RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4268b98a-ac0e-4a17-ad5f-53d1eb95ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9669423.213467956\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b0f9cb1-d513-492b-89eb-8a9a3d88ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz tylko kolumny prediction i Price do pliku CSV\n",
    "predictions.select(\"prediction\", \"Price\").write.csv(\"experiment_results.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb3b4bf-1fa4-475b-be96-b71d36f2dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Experiment 1: 6167195.447187548\n"
     ]
    }
   ],
   "source": [
    "# Eksperyment 1: Tylko cechy numeryczne\n",
    "selected_features_1 = [\"Surface\", \"Number_of_Rooms\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=selected_features_1, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "model = rf.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE for Experiment 1: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ebea0e9-8d12-4653-837b-2778a6ba6a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Experiment 2: 8625881.46598957\n"
     ]
    }
   ],
   "source": [
    "# Usuwanie kolumn, jeśli już istnieją\n",
    "df = df.drop(\"Voivodeship_index\", \"City_index\", \"features\")\n",
    "\n",
    "# Kodowanie zmiennych kategorycznych\n",
    "indexer_voivodeship = StringIndexer(inputCol=\"Voivodeship\", outputCol=\"Voivodeship_index\")\n",
    "indexer_city = StringIndexer(inputCol=\"City\", outputCol=\"City_index\")\n",
    "\n",
    "# Aplikowanie StringIndexer\n",
    "df = indexer_voivodeship.fit(df).transform(df)\n",
    "df = indexer_city.fit(df).transform(df)\n",
    "\n",
    "selected_features_2 = [\"Surface\", \"Number_of_Rooms\", \"Voivodeship_index\", \"City_index\"]\n",
    "assembler = VectorAssembler(inputCols=selected_features_2, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "model = rf.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE for Experiment 2: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f2c1c3f-f965-4c58-8723-5c4aaa726777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Experiment 3: 6289448.386006473\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# Usuwanie kolumn, jeśli już istnieją\n",
    "df = df.drop(\"Voivodeship_index\", \"City_index\", \"features\", \"Voivodeship_ohe\", \"City_ohe\")\n",
    "\n",
    "# Indeksowanie zmiennych kategorycznych\n",
    "indexer_voivodeship = StringIndexer(inputCol=\"Voivodeship\", outputCol=\"Voivodeship_index\")\n",
    "indexer_city = StringIndexer(inputCol=\"City\", outputCol=\"City_index\")\n",
    "\n",
    "df = indexer_voivodeship.fit(df).transform(df)\n",
    "df = indexer_city.fit(df).transform(df)\n",
    "\n",
    "# OneHotEncoder\n",
    "encoder_voivodeship = OneHotEncoder(inputCol=\"Voivodeship_index\", outputCol=\"Voivodeship_ohe\")\n",
    "encoder_city = OneHotEncoder(inputCol=\"City_index\", outputCol=\"City_ohe\")\n",
    "\n",
    "df = encoder_voivodeship.fit(df).transform(df)\n",
    "df = encoder_city.fit(df).transform(df)\n",
    "\n",
    "selected_features_3 = [\"Surface\", \"Number_of_Rooms\", \"Voivodeship_ohe\", \"City_ohe\"]\n",
    "assembler = VectorAssembler(inputCols=selected_features_3, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "model = rf.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE for Experiment 3: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d35f16f-8048-4dca-8d44-e9fb1139bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/25 10:29:26 WARN Instrumentation: [e69d2f17] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/12/25 10:29:26 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/12/25 10:29:26 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/12/25 10:29:26 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "24/12/25 10:29:26 WARN Instrumentation: [e69d2f17] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear Regression: 6324574.014895729\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Price\")\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "lr_rmse = evaluator.evaluate(lr_predictions)\n",
    "print(f\"RMSE for Linear Regression: {lr_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
